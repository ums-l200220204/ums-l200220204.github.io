{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c552fdc9-d5c2-4474-be20-f622e79a4034",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c552fdc9-d5c2-4474-be20-f622e79a4034",
        "outputId": "d938ad57-71ca-4e41-c902-9135cc31090d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   date_time            sender  \\\n",
            "0        NaN  62 858-0354-3008   \n",
            "1        NaN  62 858-0354-3008   \n",
            "2        NaN  62 812-1526-7243   \n",
            "3        NaN  62 812-3354-4829   \n",
            "4        NaN  62 812-1526-7243   \n",
            "\n",
            "                                             message  Cluster_3  Cluster_4  \\\n",
            "0                             media tidak disertakan          1          1   \n",
            "1   open recruitment pengurus himatif ums 2022   ...          0          0   \n",
            "2       halo kawan\" ntar malem kumpul nongkrong yokk          0          0   \n",
            "3                                        dimana tuh?          0          0   \n",
            "4                                         besti kopi          0          0   \n",
            "\n",
            "   Cluster_5  \n",
            "0          1  \n",
            "1          0  \n",
            "2          0  \n",
            "3          0  \n",
            "4          0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'data_group_cleaned.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Preprocess the text data (cleaning the \"Pesan\" column)\n",
        "try:\n",
        "    data['message'] = data['message'].fillna(\"\").str.lower()  # Fill NaN and convert to lowercase\n",
        "except KeyError:\n",
        "    print(\"Column 'Pesan' not found. Check your CSV file for the correct column name.\")\n",
        "\n",
        "# Step 2: Convert the \"Pesan\" column into numerical representation using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "# Replace 'column_name' with the actual column name ('Pesan' in this case)\n",
        "X = vectorizer.fit_transform(data['message'])\n",
        "\n",
        "# Step 3: Perform KMeans clustering with 3, 4, and 5 clusters\n",
        "clusters = {}\n",
        "for n_clusters in [3, 4, 5]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    clusters[n_clusters] = kmeans.fit_predict(X)\n",
        "\n",
        "# Add cluster labels to the dataset for each KMeans run\n",
        "for n_clusters, labels in clusters.items():\n",
        "    data[f'Cluster_{n_clusters}'] = labels\n",
        "\n",
        "# Save the updated dataset to a new CSV file\n",
        "data.to_csv('data_group_clustered.csv', index=False)\n",
        "\n",
        "# Show a sample of the updated dataset with cluster labels\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83cbc975-779c-49e4-8f35-e0ccd73e8434",
      "metadata": {
        "id": "83cbc975-779c-49e4-8f35-e0ccd73e8434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24599cf-bb11-4740-c41d-9c99318cc1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil analisis telah disimpan ke cluster_analysis.csv\n",
            "   Cluster                                   Top Words\n",
            "0        1  media (543), tidak (543), disertakan (543)\n",
            "1        0            ini (293), yang (231), dan (202)\n",
            "2        2                cina (3), istri (1), aja (1)\n"
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Fungsi untuk membaca file hasil klastering dari tar\n",
        "def read_clustered_data_from_tar(tar_file_path, csv_file_name):\n",
        "    with tarfile.open(tar_file_path, \"r\") as tar:\n",
        "        extracted_file = tar.extractfile(csv_file_name)\n",
        "        if extracted_file:\n",
        "            df = pd.read_csv(extracted_file)\n",
        "            return df\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"{csv_file_name} not found in {tar_file_path}\")\n",
        "\n",
        "# Fungsi untuk mendapatkan 3 kata teratas dari setiap kluster\n",
        "def analyze_clusters(data, cluster_column, message_column):\n",
        "    analysis = []\n",
        "    for cluster_id in data[cluster_column].unique():\n",
        "        cluster_messages = data[data[cluster_column] == cluster_id][message_column].fillna(\"\").astype(str)\n",
        "        all_words = \" \".join(cluster_messages).split()\n",
        "        clean_words = [re.sub(r'[^a-zA-Z0-9]', '', word).lower() for word in all_words if len(word) > 1]\n",
        "        most_common_words = Counter(clean_words).most_common(3)\n",
        "        analysis.append({\n",
        "            \"Cluster\": cluster_id,\n",
        "            \"Top Words\": \", \".join([f\"{word} ({count})\" for word, count in most_common_words])\n",
        "        })\n",
        "    return pd.DataFrame(analysis)\n",
        "\n",
        "# File TAR dan nama file hasil klastering di dalamnya\n",
        "tar_file_path = \"data_group.tar\"\n",
        "clustered_file_name = \"data_group_clustered.csv\"\n",
        "\n",
        "# Analisis data hasil klastering\n",
        "try:\n",
        "    df = read_clustered_data_from_tar(tar_file_path, clustered_file_name)\n",
        "    cluster_analysis = analyze_clusters(df, cluster_column=\"Cluster_3\", message_column=\"message\")\n",
        "\n",
        "    # Simpan hasil analisis ke CSV\n",
        "    analysis_csv_path = \"cluster_analysis.csv\"\n",
        "    cluster_analysis.to_csv(analysis_csv_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"Hasil analisis telah disimpan ke {analysis_csv_path}\")\n",
        "    print(cluster_analysis)\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi kesalahan: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1pJfonqZoUpS"
      },
      "id": "1pJfonqZoUpS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}